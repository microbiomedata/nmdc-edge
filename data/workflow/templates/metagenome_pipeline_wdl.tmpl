import "rqcfilter.wdl" as readsQC
import "readsqc_preprocess.wdl" as readsqc_preprocess
import "ReadbasedAnalysis.wdl" as readbasedAnalysis
import "readbasedanalysis_preprocess.wdl" as readbasedanalysis_preprocess
import "jgi_assembly.wdl" as metaAssembly
import "annotation_full.wdl" as metaAnnotation
import "annotation_output.wdl" as metaAnnotationOutput
import "mbin_nmdc.wdl" as metaMAGs
import "viral-plasmid_wf.wdl" as viralPlasmid
import "mbin_nmdc_output.wdl" as metaMAGsOutput

workflow main_workflow {
	# Workflow Booleans

	Boolean input_interleaved = true
	String? proj = "metagenome_workflow" 
    String? activity_id = "${proj}"  # "nmdc:GpXXXXXXXx"
    String? informed_by = "gold:GpXXXXXXX"
    String resource = "SDSC - Expanse"
    
    # https://nmdc-edge.org/projects/pCxA9JY0P0SckQQR/output/ReadbasedAnalysis/Readsbased_NMDC_test.json
    String url_root = "https://nmdc-edge.org/projects/"
    String url_base = url_root + sub(proj, "[^A-Za-z0-9]", "_") + "/output/"
    String git_url = "https://gitlab.com/edge-lanl/nmdc-edge"
	
	## Fastq input files
	Array[File] input_files
	
	call start {
		input: container="microbiomedata/workflowmeta:1.0.5.1"
	}


	## QC workflow
	String? readsQC_outdir
	String readsQC_bbtools_container="microbiomedata/bbtools:38.96"
	String readsQC_database="/refdata"
	String readsQC_memory="60g"
	String readsQC_threads="4"
	Array[File] input_fq1=[]
	Array[File] input_fq2=[]

    call readsqc_preprocess.readsqc_preprocess as readsqc_preprocess {
        input:
            input_files=input_files,
            outdir=readsQC_outdir,
            input_interleaved=input_interleaved,
            input_fq1=input_fq1,
            input_fq2=input_fq2
        }
    scatter (file in select_first([readsqc_preprocess.input_files_gz, [""]])) {

        call readsQC.nmdc_rqcfilter  as nmdc_rqcfilter_call {
            input:
                input_files=file,
                database=readsQC_database,
                proj=proj,
       }

    }

	## ReadbasedAnalysis workflow
	Map[String, Boolean] readbasedAnalysis_enabled_tools = {
		"gottcha2": true,
		"kraken2": true,
		"centrifuge": true
	}
    File readbasedAnalysis_reads = nmdc_rqcfilter_call.filtered_final[0]
	String ReadbasedAnalysis_container = "poeli/nmdc_taxa_profilers:1.0.5"
	Int readbasedAnalysis_cpu = 4
	String readbasedAnalysis_prefix
	String readbasedAnalysis_outdir
	Boolean? readbasedAnalysis_paired = true
	String db_gottcha2 = "/refdata/GOTTCHA2/RefSeq-r90.cg.BacteriaArchaeaViruses.species.fna"
	String db_kraken2 = "/refdata/Kraken2"
	String db_centrifuge = "/refdata/Centrifuge/hpv"


    call readbasedAnalysis.ReadbasedAnalysis as ReadbasedAnalysis_call {
        input:
            input_file=readbasedAnalysis_reads,
            cpu=readbasedAnalysis_cpu,
            proj=readbasedAnalysis_prefix,
            paired=readbasedAnalysis_paired,
            docker=ReadbasedAnalysis_container,
            bbtools_container=readsQC_bbtools_container,
            db_gottcha2=db_gottcha2, db_kraken2=db_kraken2, db_centrifuge=db_centrifuge
    }


	## Assembly workflow
	File metaAssembly_input_file = nmdc_rqcfilter_call.filtered_final[0]
	String? metaAssembly_outdir
	String metaAssembly_rename_contig_prefix="scaffold"
	Float metaAssembly_uniquekmer=1000
	String metaAssembly_bbtools_container="microbiomedata/bbtools:38.96"
	String metaAssembly_spades_container="microbiomedata/spades:3.15.0"
	String metaAssembly_memory="100g"
	String metaAssembly_threads="4"
	Array[File] metaAssembly_input_fq1=[]
	Array[File] metaAssembly_input_fq2=[]


    call metaAssembly.jgi_metaASM as metaAssembly_call {
        input:
            proj=proj,
            input_file=metaAssembly_input_file,
            outdir=metaAssembly_outdir,
            rename_contig_prefix=metaAssembly_rename_contig_prefix,
            uniquekmer=metaAssembly_uniquekmer,
            bbtools_container=metaAssembly_bbtools_container,
            spades_container=metaAssembly_spades_container,
            memory=metaAssembly_memory,
            threads=metaAssembly_threads
    }
	##Viral Plasmid Workflow
	File?   virusPlasmid_input =  metaAssembly_call.contig
	Map[String, Boolean] virusPlasmid_options = {
		"default": true,
		"relaxed": false,
		"conservative": false,
		"custom": false
	  }
	String  virusPlasmid_outdir
	Int     virusPlasmid_cpu=8
	String  virusPlasmid_database_location="/refdata"
	call viralPlasmid.viral as viralPlasmid_call {
			input:
				fasta=virusPlasmid_input,
				outdir=virusPlasmid_outdir,
				option=virusPlasmid_options,
				cpu=virusPlasmid_cpu,
				database=virusPlasmid_database_location
		}


	## Annotation workflow
	File?  metaAnnotation_imgap_input_fasta =  metaAssembly_call.contig
	String  metaAnnotation_imgap_project_id
	String  metaAnnotation_outdir
	Int     metaAnnotation_additional_threads=8
	String  metaAnnotation_database_location="/refdata/img/"


    call metaAnnotation.annotation as metaAnnotation_call {
        input:
            input_file=metaAnnotation_imgap_input_fasta,
            proj=metaAnnotation_imgap_project_id,
            imgap_project_id=metaAnnotation_imgap_project_id,
            additional_threads=metaAnnotation_additional_threads,
            database_location=metaAnnotation_database_location
    }
    call metaAnnotationOutput.annotation_output as annotation_output {
      input:
          imgap_project_type=metaAnnotation_imgap_project_id,
          outdir=metaAnnotation_outdir,
          final_stats_tsv=metaAnnotation_call.stats_tsv,
          functional_gff=metaAnnotation_call.functional_gff
  }

	
	## MAGs workflow
	String? metaMAGs_outdir
	String  metaMAGs_proj
	File? metaMAGs_contig_file =  metaAssembly_call.contig
	File? metaMAGs_sam_file =metaAssembly_call.bam
	File? metaMAGs_gff_file = metaAnnotation_call.functional_gff
	File? metaMAGs_proteins_file = metaAnnotation_call.proteins_faa
    File? metaMAGs_cog_file = metaAnnotation_call.cog_gff
    File? metaMAGs_ec_file = metaAnnotation_call.ec_tsv
    File? metaMAGs_ko_file = metaAnnotation_call.ko_tsv
    File? metaMAGs_pfam_file = metaAnnotation_call.pfam_gff
    File? metaMAGs_tigrfam_file = metaAnnotation_call.tigrfam_gff
    File? metaMAGs_cath_funfam_file = metaAnnotation_call.cath_funfam_gff
    File? metaMAGs_smart_file = metaAnnotation_call.smart_gff
    File? metaMAGs_supfam_file = metaAnnotation_call.supfam_gff
    File? metaMAGs_product_names_file = metaAnnotation_call.product_names_tsv
    File? metaMAGs_gene_phylogeny_file = metaAnnotation_call.gene_phylogeny_tsv
    File? metaMAGs_lineage_file = metaAnnotation_call.lineage_tsv
	File? metaMAGs_map_file
	File? metaMAGs_domain_file
	Int metaMAGs_cpu=16
	Int metaMAGs_threads=64
	Int metaMAGs_pthreads=1
	String metaMAGs_database="/refdata/GTDBTK_DB/gtdbtk_release207_v2"
    String checkm_db="/refdata/CheckM_DB/checkm_data_2015_01_16"
    String metaMAGs_container = "microbiomedata/nmdc_mbin@sha256:c8df293e80698627ce66df7cd07f6b10e9112184e3bf1379e615d10123f7bc64"
	

    call metaMAGs.nmdc_mags as metaMAGs_call {
        input:
            proj_name=metaMAGs_proj,
            contig_file=metaMAGs_contig_file,
            sam_file=metaMAGs_sam_file,
            gff_file=metaMAGs_gff_file,
            proteins_file=metaMAGs_proteins_file,
            cog_file=metaMAGs_cog_file,
            ec_file=metaMAGs_ec_file,
            ko_file=metaMAGs_ko_file,
            pfam_file=metaMAGs_pfam_file,
            tigrfam_file=metaMAGs_tigrfam_file,
            cath_funfam_file=metaMAGs_cath_funfam_file,
            smart_file=metaMAGs_smart_file,
            supfam_file=metaMAGs_supfam_file,
            product_names_file=metaMAGs_product_names_file,
            gene_phylogeny_file=metaMAGs_gene_phylogeny_file,
            lineage_file=metaMAGs_lineage_file,
            map_file=metaMAGs_map_file,
            domain_file=metaMAGs_domain_file,
            cpu=metaMAGs_cpu,
            threads=metaMAGs_threads,
            pthreads=metaMAGs_pthreads,
            gtdbtk_db=metaMAGs_database,
            checkm_db=checkm_db,
            scratch_dir=metaMAGs_outdir,
            container=metaMAGs_container
    }

	call finish {
		input: container="microbiomedata/workflowmeta:1.0.5.1",
			proj= metaAssembly_rename_contig_prefix,
			start=start.start,
			resource=resource,
			url_base=url_base,
			git_url=git_url,
			informed_by=informed_by,
			read = if (input_interleaved) then input_files else flatten([input_fq1,input_fq2]),
			filtered = nmdc_rqcfilter_call.filtered_final,
			filtered_stats = nmdc_rqcfilter_call.filtered_stats_final,
			filtered_stats2 = nmdc_rqcfilter_call.filtered_stats2_final,
			filtered_stats_json = nmdc_rqcfilter_call.filtered_stats_json_final,
			fasta=metaAssembly_call.contig,
			scaffold=metaAssembly_call.scaffold,
			agp=metaAssembly_call.agp,
			bam=metaAssembly_call.bam,
			covstats=metaAssembly_call.covstats,
			proteins_faa=metaAnnotation_call.proteins_faa,
			functional_gff=metaAnnotation_call.functional_gff,
			structural_gff=metaAnnotation_call.structural_gff,
			ko_tsv=metaAnnotation_call.ko_tsv,
			ec_tsv=metaAnnotation_call.ec_tsv,
			cog_gff=metaAnnotation_call.cog_gff,
			pfam_gff=metaAnnotation_call.pfam_gff,
			tigrfam_gff=metaAnnotation_call.tigrfam_gff,
			smart_gff=metaAnnotation_call.smart_gff,
			supfam_gff=metaAnnotation_call.supfam_gff,
			cath_funfam_gff=metaAnnotation_call.cath_funfam_gff,
			crt_gff=metaAnnotation_call.crt_gff,
			genemark_gff=metaAnnotation_call.genemark_gff,
			prodigal_gff=metaAnnotation_call.prodigal_gff,
			trna_gff=metaAnnotation_call.trna_gff,
			crt_crisprs=metaAnnotation_call.crt_crisprs,
			product_names_tsv=metaAnnotation_call.product_names_tsv,
			gene_phylogeny_tsv=metaAnnotation_call.gene_phylogeny_tsv,
			ko_ec_gff=metaAnnotation_call.ko_ec_gff,
			stats_tsv=metaAnnotation_call.stats_tsv,
			# stats_json=metaAnnotation_call.stats_json,
			gottcha2_report_tsv = ReadbasedAnalysis_call.final_gottcha2_report_tsv,
			gottcha2_full_tsv = ReadbasedAnalysis_call.final_gottcha2_full_tsv,
			gottcha2_krona_html = ReadbasedAnalysis_call.final_gottcha2_krona_html,
			centrifuge_classification_tsv = ReadbasedAnalysis_call.final_centrifuge_classification_tsv,
			centrifuge_report_tsv = ReadbasedAnalysis_call.final_centrifuge_report_tsv,
			centrifuge_krona_html = ReadbasedAnalysis_call.final_centrifuge_krona_html,
			kraken2_classification_tsv = ReadbasedAnalysis_call.final_kraken2_classification_tsv,
			kraken2_report_tsv = ReadbasedAnalysis_call.final_kraken2_report_tsv,
			kraken2_krona_html = ReadbasedAnalysis_call.final_kraken2_krona_html,
			short=metaMAGs_call.short,
			lowdepth=metaMAGs_call.low,
			unbinned=metaMAGs_call.final_unbinned_fa,
			checkm=metaMAGs_call.final_checkm,
			bac_summary = metaMAGs_call.final_gtdbtk_bac_summary,
			ar_summary = metaMAGs_call.final_gtdbtk_ar_summary,
			final_hqmq_bins = metaMAGs_call.final_hqmq_bins_zip,
			final_hqmq_bins = metaMAGs_call.final_hqmq_bins_zip,
			mags_stats_json=metaMAGs_call.final_stats_json,
			hqmq_bin_fasta_files=metaMAGs_call.final_hqmq_bins_zip,
			bin_fasta_files=metaMAGs_call.final_lq_bins_zip,
			qadir=readsQC_outdir,
			assemdir=metaAssembly_outdir,
			annodir=metaAnnotation_outdir,
			magsdir=metaMAGs_outdir,
			rbadir=readbasedAnalysis_outdir
	}
}

task split_interleaved_fastq{
	Array[File] reads
	String container
	String? memory = "4G"
	String output1 = "input.left.fastq.gz"
	String output2 = "input.right.fastq.gz"

	runtime {
		docker: container
		mem: "4 GiB"
		cpu:  1	 
	}
	command {
		 cat ${sep=" " reads} > infile.fastq.gz	
		 reformat.sh -Xmx${default="10G" memory} in=infile.fastq.gz out1=${output1} out2=${output2}
	}
	
	output {
		Array[File] outFastq = [output1, output2]
	}
}

task interleave_reads{

	Array[File] input_files
	String output_file = "interleaved.fastq.gz"
	String container
	
	command <<<
		if file --mime -b ${input_files[0]} | grep gzip > /dev/null ; then 
			paste <(gunzip -c ${input_files[0]} | paste - - - -) <(gunzip -c ${input_files[1]} | paste - - - -) | tr '\t' '\n' | gzip -c > ${output_file}
			echo ${output_file}
		else
			if [[ "${output_file}" == *.gz ]]; then
				paste <(cat ${input_files[0]} | paste - - - -) <(cat ${input_files[1]} | paste - - - -) | tr '\t' '\n' | gzip -c > ${output_file}
				echo ${output_file}
			else
				paste <(cat ${input_files[0]} | paste - - - -) <(cat ${input_files[1]} | paste - - - -) | tr '\t' '\n' | gzip -c > ${output_file}.gz
				echo ${output_file}.gz
			fi
		fi
	>>>
	
	runtime {
		docker: container
		memory: "1 GiB"
		cpu:  1
	}
	
	output {
		File out_fastq = read_string(stdout())
	}
}

task start {
	String container
	command <<<
		set -e
		# Capture the start time
		date --iso-8601=seconds > start.txt
	>>>
	output{
		String start = read_string("start.txt")
		File start_file = "start.txt"
	}
	runtime {
		memory: "1 GiB"
		cpu:  1
		maxRetries: 1
		docker: container
	}
}


task finish {
	String container
	String proj
	String prefix=sub(proj, ":", "_")
	String start
	String informed_by
	String resource
	String url_base
	String git_url
	Array[File] read
	Array[File?] filtered
	Array[File?] filtered_stats
	Array[File?] filtered_stats2
	Array[File?] filtered_stats_json
	File? fasta
	File? scaffold
	File? agp
	File? bam
	File? covstats
	File? proteins_faa
	File? structural_gff
	File? functional_gff
	File? ko_tsv
	File? ec_tsv
	File? cog_gff
	File? pfam_gff
	File? tigrfam_gff
	File? smart_gff
	File? supfam_gff
	File? cath_funfam_gff
	File? crt_gff
	File? genemark_gff
	File? prodigal_gff
	File? trna_gff
	File? rrna_gff
	File? ncrna_tmrna_gff
	File? ko_ec_gff
	File? stats_tsv
	File? stats_json
	File? gene_phylogeny_tsv
	File? product_names_tsv
	File? crt_crisprs
	File? short
	File? lowdepth
	File? unbinned
	File? checkm
	File? bac_summary
	File? ar_summary
	File? final_hqmq_bins
	File? mags_stats_json
	Array[File?] hqmq_bin_fasta_files
	Array[File?] bin_fasta_files
	File? gottcha2_report_tsv
	File? gottcha2_full_tsv
	File? gottcha2_krona_html
	File? centrifuge_classification_tsv
	File? centrifuge_report_tsv
	File? centrifuge_krona_html
	File? kraken2_classification_tsv
	File? kraken2_report_tsv
	File? kraken2_krona_html
	Int n_hqmq = length(hqmq_bin_fasta_files)
	Int n_bin = length(bin_fasta_files)
	String qadir="ReadsQC/"
	String assemdir="MetagenomeAssembly/"
	String annodir="MetagenomeAnnotation/"
	String magsdir="MetagenomeMAGs/"
	String rbadir="ReadbasedAnalysis/"
	String sed_bin="s/bins./${prefix}_/g"
	String dollar ="$"

	command <<<
		set -e
		mkdir -p ${annodir}
		mkdir -p ${assemdir}
		mkdir -p ${qadir}
		mkdir -p ${annodir}
		mkdir -p ${rbadir}
		end=`date --iso-8601=seconds`
	

		# Generate QA objects
			/scripts/rqcstats.py ${select_first(filtered_stats)} > stats.json
			/scripts/generate_objects.py --type "qa" --id ${informed_by} \
				--name "Read QC Activity for ${proj}" --part ${proj} \
				--start ${start} --end $end \
				--resource '${resource}' --url ${url_base} --giturl ${git_url} \
				--extra stats.json \
				--inputs ${sep=' ' read} \
				--outputs \
				${select_first(filtered)} 'Filtered Reads' \
				${select_first(filtered_stats)} 'Filtered Stats'
			cp activity.json data_objects.json ${qadir}/
            for i in ${sep=' ' filtered}
			do
				f=${dollar}(basename $i)
				dir=${dollar}(dirname $i)
				prefix=${dollar}{f%_filtered.fastq.gz}
				mkdir -p ${qadir}/$prefix
                cp -f $i ${qadir}/$prefix
                cp -f $dir/${dollar}{prefix}_filterStats.txt  ${qadir}/$prefix/filterStats.txt
                cp -f $dir/${dollar}{prefix}_filterStats2.txt  ${qadir}/$prefix/filterStats2.txt
                cp -f $dir/${dollar}{prefix}_qa_stats.json ${qadir}/$prefix/filterStats.json

            done

		

			# Generate assembly objects
			/scripts/generate_objects.py --type "assembly" --id ${informed_by} \
				--name "Assembly Activity for ${proj}" --part ${proj} \
				--start ${start} --end $end \
				--resource '${resource}' --url ${url_base} --giturl ${git_url} \
				--inputs ${sep=" " filtered} \
				--outputs \
				${covstats} 'Metagenome Contig Coverage Stats' \
				${fasta} 'Assembled contigs fasta' \
				${scaffold} 'Assembled scaffold fasta' \
				${agp} 'Assembled AGP file' \
				${bam} 'Metagenome Alignment BAM file'
			cp activity.json data_objects.json ${assemdir}/



			# Generate annotation objects
			nmdc gff2json ${functional_gff} -of features.json -oa annotations.json -ai ${informed_by}

			/scripts/generate_objects.py --type "annotation" --id ${informed_by} \
				--name "Annotation Activity for ${proj}" --part ${proj} \
				--start ${start} --end $end \
				--resource '${resource}' --url ${url_base} --giturl ${git_url} \
				--inputs ${fasta} \
				--outputs \
				${proteins_faa} 'Protein FAA' \
				${structural_gff} 'Structural annotation GFF file' \
				${functional_gff} 'Functional annotation GFF file' \
				${ko_tsv} 'KO TSV file' \
				${ec_tsv} 'EC TSV file' \
				${cog_gff} 'COG GFF file' \
				${pfam_gff} 'PFAM GFF file' \
				${tigrfam_gff} 'TigrFam GFF file' \
				${smart_gff} 'SMART GFF file' \
				${supfam_gff} 'SuperFam GFF file' \
				${cath_funfam_gff} 'Cath FunFam GFF file' \
				${crt_gff} 'CRT GFF file' \
				${genemark_gff} 'Genemark GFF file' \
				${prodigal_gff} 'Prodigal GFF file' \
				${trna_gff} 'tRNA GFF File' \
				${crt_crisprs} 'CRISPRS file' \
				${product_names_tsv} 'Product Names tsv' \
				${gene_phylogeny_tsv} 'Gene Phylogeny tsv' \
				${ko_ec_gff} 'KO_EC GFF file'

			#cp ${proteins_faa} ${structural_gff} ${functional_gff} \
			#	${ko_tsv} ${ec_tsv} ${cog_gff} ${pfam_gff} ${tigrfam_gff} \
			#	${smart_gff} ${supfam_gff} ${cath_funfam_gff} ${ko_ec_gff} \
			#	${stats_tsv} ${stats_json} \
			#	${annodir}/
			cp features.json annotations.json activity.json data_objects.json ${annodir}/
		

			if [ ${n_hqmq} -gt 0 ] ; then
			    mkdir -p hqmq
				(cd hqmq && cp ${sep=" " hqmq_bin_fasta_files} .)
				(cd hqmq && for binFA in *.fa; do
					name=${dollar}{binFA/bins./}
					binID=${dollar}{name/.fa/}
					mkdir -p ${prefix}_$binID
					cp ${magsdir}/mbin_datafile_${prefix}.txt ${prefix}_$binID/.
						grep ">" $binFA | sed -e 's/>//' | grep -f - ${proteins_faa} > ${prefix}_$binID/${prefix}_$binID.faa  || true 
						grep ">" $binFA | sed -e 's/>//' | grep -f - ${structural_gff} > ${prefix}_$binID/${prefix}_$binID.functional_annotation.gff || true
						grep ">" $binFA | sed -e 's/>//' | grep -f - ${functional_gff}> ${prefix}_$binID/${prefix}_$binID.structural_annotation.gff || true
						grep ">" $binFA | sed -e 's/>//' | grep -f - ${cog_gff} > ${prefix}_$binID/${prefix}_$binID.cog.gff || true
						grep ">" $binFA | sed -e 's/>//' | grep -f - ${pfam_gff} > ${prefix}_$binID/${prefix}_$binID.pfam.gff || true
						grep ">" $binFA | sed -e 's/>//' | grep -f - ${tigrfam_gff} > ${prefix}_$binID/${prefix}_$binID.tigrfam.gff || true
						grep ">" $binFA | sed -e 's/>//' | grep -f - ${gene_phylogeny_tsv} > ${prefix}_$binID/${prefix}_$binID.gene_phylogeny.tsv || true
						grep ">" $binFA | sed -e 's/>//' | grep -f - ${ko_tsv} > ${prefix}_$binID/${prefix}_$binID.ko.tsv || true
						grep ">" $binFA | sed -e 's/>//' | grep -f - ${ec_tsv} > ${prefix}_$binID/${prefix}_$binID.ec.tsv || true
						grep ">" $binFA | sed -e 's/>//' | grep -f - ${product_names_tsv} > ${prefix}_$binID/${prefix}_$binID.product_names.tsv || true
						grep ">" $binFA | sed -e 's/>//' | grep -f - ${crt_crisprs} > ${prefix}_$binID/${prefix}_$binID.crt.crisprs || true
						mv $binFA ${prefix}_$binID/${prefix}_$binID.fna
					zip ${prefix}_$binID.zip ${prefix}_$binID/*
					done
				)
				(cd hqmq && zip ${magsdir}/${prefix}_hqmq_bins.zip *.zip)

			fi

			#IFS=""
			/scripts/generate_objects.py --type "MAGs" --id ${informed_by} \
				--name "MAGs Analysis Activity for ${proj}" --part ${proj} \
				--start ${start} --end $end \
				--resource '${resource}' --url ${url_base} --giturl ${git_url} \
				--inputs ${fasta} ${bam} ${functional_gff} \
				--outputs \
				${magsdir}/${prefix}_bins.tooShort.fa "tooShort (< 3kb) filtered contigs fasta file by metaBat2" \
				${magsdir}/${prefix}_bins.lowDepth.fa "lowDepth (mean cov <1 )  filtered contigs fasta file by metabat2" \
				${magsdir}/${prefix}_bins.unbinned.fa "unbinned fasta file from metabat2" \
				${magsdir}/${prefix}_hqmq_bins.zip "high-quality and medium-quality bins" \
				${magsdir}/${prefix}_checkm_qa.out "metabat2 bin checkm quality assessment result" \
				${" " + bac_summary + " \"gtdbtk bacterial assignment result summary table\""} \
				${" " + ar_summary + " \"gtdbtk archaea assignment result summary table\""}
        cp ${lowdepth}  ${magsdir}/${proj}_bins.lowDepth.fa
        cp ${short} ${magsdir}/${proj}_bins.tooShort.fa
        cp ${unbinned} ${magsdir}/${proj}_bins.unbinned.fa
        cp ${checkm} ${magsdir}/${proj}_checkm_qa.out
			cp activity.json data_objects.json ${lowdepth} ${unbinned} ${mags_stats_json} ${ar_summary} ${final_hqmq_bins} \
			${sep=" " hqmq_bin_fasta_files} ${sep=" " bin_fasta_files}  ${magsdir}/

		    mkdir -p ${rbadir}
			/scripts/generate_objects.py --type "ReadbasedAnalysis" --id ${informed_by} \
				--name "ReadBased Analysis Activity for ${proj}" --part ${proj} \
				--start ${start} --end $end \
				--resource '${resource}' --url ${url_base} --giturl ${git_url} \
				--inputs ${sep=" " filtered} \
				--outputs \
				${gottcha2_report_tsv} "Gottcha2 TSV report" \
				${gottcha2_full_tsv} "Gottcha2 full TSV report" \
				${gottcha2_krona_html} "Gottcha2 Krona HTML report" \
				${centrifuge_classification_tsv} "Centrifuge classification TSV report" \
				${centrifuge_report_tsv} "Centrifuge TSV report" \
				${centrifuge_krona_html} "Centrifuge Krona HTML report" \
				${kraken2_classification_tsv} "Kraken classification TSV report" \
				${kraken2_report_tsv} "Kraken2 TSV report" \
				${kraken2_krona_html} "Kraken2 Krona HTML report"

			cp activity.json data_objects.json  ${rbadir}/
			cp ${gottcha2_report_tsv} ${gottcha2_full_tsv} ${gottcha2_krona_html} ${rbadir}/
			cp ${centrifuge_classification_tsv} ${centrifuge_report_tsv} ${centrifuge_krona_html} ${rbadir}/
			cp ${kraken2_classification_tsv} ${kraken2_report_tsv} ${kraken2_krona_html} ${rbadir}/

	>>>

	runtime {
		memory: "60 GiB"
		cpu:  4
		maxRetries: 1
		docker: container
	}
}
